{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "device = torch.device('mps') if torch.backends.mps.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = YOLO(\"runs/detect/train2/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"visualization_trial\"\n",
    "image_paths = [os.path.join(image_folder, f) for f in os.listdir(image_folder) if f.endswith('.jpeg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = final_model.predict(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial[6].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the input video\n",
    "input_video_path = \"visualization_trial/IMG_4650.mp4\"\n",
    "output_video_path = \"demo.mp4\"\n",
    "\n",
    "# Load the YOLO model and predict on the video stream\n",
    "video = final_model.predict(input_video_path, stream=True)\n",
    "\n",
    "# Initialize the VideoCapture to get video properties\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Video frame width\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # Video frame height\n",
    "cap.release()\n",
    "\n",
    "# Initialize OpenCV VideoWriter\n",
    "out = cv2.VideoWriter(\n",
    "    output_video_path,\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'),  # Codec for .mp4 files\n",
    "    fps,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "\n",
    "# Process and write each frame to the output video\n",
    "for result in video:\n",
    "    # Plot the frame with YOLO predictions\n",
    "    frame = result.plot()  # Adds bounding boxes to the frame\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "# Release the VideoWriter\n",
    "out.release()\n",
    "print(f\"Processed video saved to: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Path to the input video\n",
    "input_video_path = \"visualization_trial/IMG_4650.mp4\"\n",
    "output_video_path = \"demo.mp4\"\n",
    "\n",
    "# Load the YOLO model and predict on the video stream\n",
    "video = final_model.predict(input_video_path, stream=True)\n",
    "\n",
    "# Initialize the VideoCapture to get video properties\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Video frame width\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # Video frame height\n",
    "cap.release()\n",
    "\n",
    "# Initialize OpenCV VideoWriter\n",
    "out = cv2.VideoWriter(\n",
    "    output_video_path,\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'),  # Codec for .mp4 files\n",
    "    fps,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "\n",
    "# Helper function to check if a bounding box is inside another\n",
    "def is_inside(box1, box2):\n",
    "    \"\"\"\n",
    "    Check if box1 is inside box2\n",
    "    box = [x_min, y_min, x_max, y_max]\n",
    "    \"\"\"\n",
    "    return box1[0] >= box2[0] and box1[1] >= box2[1] and box1[2] <= box2[2] and box1[3] <= box2[3]\n",
    "\n",
    "# Process and write each frame to the output video\n",
    "for result in video:\n",
    "    frame = result.orig_img.copy()  # Original frame without bounding boxes\n",
    "    \n",
    "    hand_cards = []  # Cards detected in the hand\n",
    "    flop_cards = []  # Cards detected in the flop\n",
    "    \n",
    "    # Find bounding boxes and class names\n",
    "    boxes = result.boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n",
    "    classes = result.boxes.cls.cpu().numpy()  # Class indices\n",
    "    labels = result.names  # Class label names\n",
    "\n",
    "    hand_box = None\n",
    "    flop_box = None\n",
    "    \n",
    "    # Identify \"HAND\" and \"FLOP\" bounding boxes\n",
    "    for i, cls_idx in enumerate(classes):\n",
    "        cls_name = labels[int(cls_idx)]\n",
    "        if cls_name == \"hand\":\n",
    "            hand_box = boxes[i]\n",
    "        elif cls_name == \"flop\":\n",
    "            flop_box = boxes[i]\n",
    "    \n",
    "    # Identify cards inside HAND and FLOP\n",
    "    for i, cls_idx in enumerate(classes):\n",
    "        cls_name = labels[int(cls_idx)]\n",
    "        if cls_name != \"hand\" and cls_name != \"flop\":\n",
    "            card_box = boxes[i]\n",
    "\n",
    "            try:\n",
    "                if hand_box is not None and is_inside(card_box, hand_box):\n",
    "                    print(hand_box)\n",
    "                    hand_cards.append(cls_name)\n",
    "                elif flop_box is not None and is_inside(card_box, flop_box):\n",
    "                    print(flop_box)\n",
    "                    flop_cards.append(cls_name)\n",
    "            except:\n",
    "                raise Exception(f\"Error processing frame\")\n",
    "            finally:\n",
    "                print(\"Hand\", hand_box)\n",
    "                print(\"Flop\", flop_box)\n",
    "                print(\"Card\", card_box)\n",
    "\n",
    "    # Add bounding boxes to the frame\n",
    "    frame_with_boxes = result.plot()\n",
    "\n",
    "    # Prepare text for HAND and FLOP\n",
    "    hand_text = \"HAND: \" + \", \".join(hand_cards) if hand_cards else \"HAND: None\"\n",
    "    flop_text = \"FLOP: \" + \", \".join(flop_cards) if flop_cards else \"FLOP: None\"\n",
    "\n",
    "    # Overlay text on the frame\n",
    "    cv2.putText(frame_with_boxes, hand_text, (50, frame_height - 100),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame_with_boxes, flop_text, (50, frame_height - 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(frame_with_boxes)\n",
    "\n",
    "# Release the VideoWriter\n",
    "out.release()\n",
    "print(f\"Processed video saved to: {output_video_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Path to the input video\n",
    "input_video_path = \"visualization_trial/IMG_4650.mp4\"\n",
    "output_video_path = \"demo.mp4\"\n",
    "\n",
    "# Load the YOLO model and predict on the video stream\n",
    "video = final_model.predict(input_video_path, stream=True)\n",
    "\n",
    "# Initialize the VideoCapture to get video properties\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # Frames per second\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))  # Video frame width\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  # Video frame height\n",
    "cap.release()\n",
    "\n",
    "# Initialize OpenCV VideoWriter\n",
    "out = cv2.VideoWriter(\n",
    "    output_video_path,\n",
    "    cv2.VideoWriter_fourcc(*'mp4v'),  # Codec for .mp4 files\n",
    "    fps,\n",
    "    (frame_width, frame_height)\n",
    ")\n",
    "\n",
    "# Helper function to check if a bounding box is inside another\n",
    "def is_inside(box1, box2):\n",
    "    \"\"\"\n",
    "    Check if box1 is inside box2\n",
    "    box = [x_min, y_min, x_max, y_max]\n",
    "    \"\"\"\n",
    "    return box1[0] >= box2[0] and box1[1] >= box2[1] and box1[2] <= box2[2] and box1[3] <= box2[3]\n",
    "\n",
    "\n",
    "def weighted_rolling_average(data):\n",
    "    \"\"\"\n",
    "    Calculate a weighted moving average for a list of floats.\n",
    "    Weights increase toward the end of the list.\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    if n == 0:\n",
    "        return 0  # Handle empty lists\n",
    "    \n",
    "    # Generate weights that increase linearly: [1, 2, ..., n]\n",
    "    weights = np.arange(1, n + 1)\n",
    "    \n",
    "    # Compute weighted average: sum(data[i] * weight[i]) / sum(weights)\n",
    "    weighted_avg = np.dot(data, weights) / weights.sum()\n",
    "    \n",
    "    # Adjust for streak length by multiplying by log(n + 1) to favor longer streaks\n",
    "    adjusted_avg = weighted_avg * np.log1p(n)  # log1p(x) is log(1 + x) to avoid issues with small n\n",
    "    return adjusted_avg\n",
    "\n",
    "# Memory for HAND and FLOP\n",
    "memory_hand = dict()\n",
    "memory_flop = dict()\n",
    "\n",
    "# Process and write each frame to the output video\n",
    "for result in video:\n",
    "    frame = result.orig_img.copy()  # Original frame without bounding boxes\n",
    "    \n",
    "    current_hand_cards = []  # Cards detected in the hand\n",
    "    current_flop_cards = []  # Cards detected in the flop\n",
    "    \n",
    "    # Find bounding boxes, class names, and confidence scores\n",
    "    boxes = result.boxes.xyxy.cpu().numpy()  # Bounding box coordinates\n",
    "    classes = result.boxes.cls.cpu().numpy()  # Class indices\n",
    "    confidences = result.boxes.conf.cpu().numpy()  # Confidence scores\n",
    "    labels = result.names  # Class label names\n",
    "    \n",
    "    # Identify \"HAND\" and \"FLOP\" bounding boxes\n",
    "    for i, cls_idx in enumerate(classes):\n",
    "        cls_name = labels[int(cls_idx)]\n",
    "        if cls_name == \"hand\":\n",
    "            hand_box = boxes[i]\n",
    "        elif cls_name == \"flop\":\n",
    "            flop_box = boxes[i]\n",
    "    \n",
    "    # Identify cards inside HAND and FLOP\n",
    "    for i, cls_idx in enumerate(classes):\n",
    "        cls_name = labels[int(cls_idx)]\n",
    "        if cls_name != \"hand\" and cls_name != \"flop\":\n",
    "            card_box = boxes[i]\n",
    "            confidence = confidences[i]\n",
    "            if hand_box is not None and is_inside(card_box, hand_box):\n",
    "                if cls_name not in memory_hand:\n",
    "                    memory_hand[cls_name] = []\n",
    "                memory_hand[cls_name].append(confidence)\n",
    "            elif flop_box is not None and is_inside(card_box, flop_box):\n",
    "                if cls_name not in memory_flop:\n",
    "                    memory_flop[cls_name] = []\n",
    "                memory_flop[cls_name].append(confidence)\n",
    "\n",
    "\n",
    "    avg_confidence_hand = {card: weighted_rolling_average(confidences) for card, confidences in memory_hand.items()}\n",
    "    avg_confidence_flop = {card: weighted_rolling_average(confidences) for card, confidences in memory_flop.items()}\n",
    "\n",
    "    current_hand = sorted(avg_confidence_hand, key=avg_confidence_hand.get, reverse=True)[:2]\n",
    "    current_flop = sorted(avg_confidence_flop, key=avg_confidence_flop.get, reverse=True)[:5]\n",
    "\n",
    "    # Add bounding boxes to the frame\n",
    "    frame_with_boxes = result.plot()\n",
    "\n",
    "    # Prepare text for HAND and FLOP\n",
    "    hand_text = \"HAND: \" + \", \".join(current_hand) if current_hand else \"HAND: None\"\n",
    "    flop_text = \"FLOP: \" + \", \".join(current_flop) if current_flop else \"FLOP: None\"\n",
    "\n",
    "    # Overlay text on the frame\n",
    "    cv2.putText(frame_with_boxes, hand_text, (50, frame_height - 100),\n",
    "                cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    cv2.putText(frame_with_boxes, flop_text, (50, frame_height - 50),\n",
    "                cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    # Write the processed frame to the output video\n",
    "    out.write(frame_with_boxes)\n",
    "\n",
    "# Release the VideoWriter\n",
    "out.release()\n",
    "print(f\"Processed video saved to: {output_video_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aicv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
